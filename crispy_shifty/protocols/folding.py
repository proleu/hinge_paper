# Python standard library
from operator import eq, ge, gt, le, lt, ne
from typing import Any, Dict, Iterator, List, Optional, Tuple, Union

from pyrosetta.distributed import requires_init

# 3rd party library imports
# Rosetta library imports
from pyrosetta.distributed.packed_pose.core import PackedPose
from pyrosetta.rosetta.core.pose import Pose
from pyrosetta.rosetta.core.select.residue_selector import ResidueSelector

# Custom library imports

af2_metrics = [
    "mean_pae",
    "mean_pae_interaction",
    "mean_pae_interaction_AB",
    "mean_pae_interaction_BA",
    "mean_pae_intra_chain",
    "mean_pae_intra_chain_A",
    "mean_pae_intra_chain_B",
    "mean_plddt",
    "model",
    "pTMscore",
    "recycles",
    "rmsd_to_input",
    "rmsd_to_reference",
    "seed",
    "tol",
    "type",
]


def generate_decoys_from_pose(
    pose: Pose,
    filter_dict: Dict[
        str, Tuple[Union[eq, ge, gt, le, lt, ne], Union[int, float, str]]
    ] = {},
    generate_prediction_decoys: Optional[bool] = False,
    label_first: Optional[bool] = False,
    prefix: Optional[str] = "tmp",
    rank_on: Optional[
        Union[
            str, bool
        ]  # "mean_plddt", "pTMscore", "rmsd_to_input", "rmsd_to_reference", or False
    ] = "mean_plddt",
    add_alt_model_scores: Optional[bool] = False,
    **kwargs,
) -> Iterator[Pose]:
    """
    :param: pose: Pose object to generate decoys from.
    :param: filter_dict: dictionary of filters to apply to the decoys. This is supplied
    as a dictionary of the form {'score_name': (operator, value)} where the operator is
    one of the following: eq, ge, gt, le, lt, ne. Example: {'mean_plddt': (ge, 0.9)} .
    Note that this defaults to an empty dict, which will simply return all decoys.
    :param: generate_prediction_decoys: If True, generate decoys for the predictions
    instead of threading the sequences onto the input pose.
    :param: label_first: If True, label the first decoy as designed by rosetta and the
    rest as designed by mpnn.
    prefix: for poses with many tags/pymol_names in results, get all results with the
    same prefix
    rank_on: the score to rank multiple model results for the same tag/pymol_name on.
    kwargs: keyword arguments (if they are not in the named arguments they will be ignored)
    :return: iterator of poses
    The decoys are generated by applying the filters to the model results in the pose.
    """
    import json
    import sys
    from copy import deepcopy
    from pathlib import Path

    import pyrosetta
    import pyrosetta.distributed.io as io
    from pyrosetta.rosetta.core.pose import setPoseExtraScore

    sys.path.insert(0, str(Path(__file__).resolve().parent.parent))
    from crispy_shifty.protocols.mpnn import thread_full_sequence

    if rank_on == "false":
        rank_on = False

    # get the scores from the pose that have the prefix
    scores = {k: v for k, v in pose.scores.items() if prefix in k}
    # get the scores from the pose that don't have the prefix
    pose_scores = {k: v for k, v in pose.scores.items() if prefix not in k}
    # the format we expect is
    # {'tag1': {'model_seed': json_string of scores dict, 'seq': sequence}, tag2: ...}
    # for each tag, check that the format is correct then:
    # 1. get the sequence
    # 2. get the (possibly multiple) model/seed results by loading the json_string
    # 3. sort the model/seed results by the rank_on score and take the top result only
    # 4. apply the filter(s) that result
    for i, (tag, result) in enumerate(sorted(scores.items())):
        # try to load the json string
        try:
            results = json.loads(result)
        # fail gracefully if it can't be loaded
        except json.decoder.JSONDecodeError:
            print(f"Could not load json string for {tag}")
            continue
        # for k, v in results.items():
        #     io.to_pose(io.pose_from_pdbstring(v["decoy_pdbstring"])).dump_pdb(k)
        # anything that doesn't have a seq or results is a problem, once loaded
        if "seq" not in results.keys():
            raise ValueError(
                f"{tag} does not have a sequence in the pose datacache. "
                "This is required for generating decoys."
            )
        else:
            sequence = results.pop("seq")
        # remaining should be model/seed results
        if "model_" not in list(results.keys())[0]:
            raise ValueError(
                f"{tag} does not have a model/seed in the pose datacache. "
                "This is required for generating decoys."
            )
        else:
            pass
        if not rank_on:
            # return all the decoys
            top_results = sorted([x[1] for x in results.items()], key=lambda x: x["mean_plddt"], reverse=True)
        else:
            # sort the model/seed results by the rank_on score and take the top result only
            # this is a bit tricky because higher is better for mean_plddt and pTMscore
            # and lower is better for rmsd_to_input and rmsd_to_reference
            if rank_on == "mean_plddt" or rank_on == "pTMscore":
                # higher is better
                model_seed_results = sorted(
                    results.items(), key=lambda x: x[1][rank_on], reverse=True
                )
            elif rank_on == "rmsd_to_input" or rank_on == "rmsd_to_reference":
                # lower is better
                model_seed_results = sorted(
                    results.items(), key=lambda x: x[1][rank_on], reverse=False
                )
            else:
                raise ValueError(
                    f"{rank_on} is not a valid rank_on score. "
                    "This is required for generating decoys."
                )
            # get the top result
            top_results = [deepcopy(model_seed_results[0][1])]
            if add_alt_model_scores:
                for model_seed, other_result in model_seed_results:
                    # get the scores for the other results and add to the top result
                    # include the best result so you can have all scores labeled by model, it'll then just duplicate some scores which is fine
                    for k, v in other_result.items():
                        top_results[0][f"{model_seed}__{k}"] = v
        for top_result in top_results:
            # setup flag: the decoy hasn't been discarded yet
            keep_decoy = True
            # apply the filter(s)
            for score_name, (operator, value) in filter_dict.items():
                if operator(top_result[score_name], value):
                    pass
                else:
                    # if the filter fails, don't keep the decoy
                    keep_decoy = False
                    break
            # if the decoy passes all filters, yield it
            if keep_decoy:
                if generate_prediction_decoys:
                    decoy_pdbstring = top_result.pop("decoy_pdbstring")
                    decoy = io.to_pose(io.pose_from_pdbstring(decoy_pdbstring))
                else:
                    decoy = thread_full_sequence(
                        pose,
                        sequence,
                    )
                # add the scores from the top result to the decoy
                pose_scores.update(top_result)
                if label_first:
                    if tag == "mpnn_seq_0000":
                        pose_scores["designed_by"] = "rosetta"
                    else:
                        pose_scores["designed_by"] = "mpnn"
                else:
                    pass
                pose_scores["tag"] = tag
                # clear decoy scores
                pyrosetta.rosetta.core.pose.clearPoseExtraScores(decoy)
                for k, v in pose_scores.items():
                    setPoseExtraScore(decoy, k, v)
                yield decoy
            else:
                pass
    return


def process_results_json(path: str) -> Tuple[str, str, Dict[Any, Any]]:
    """
    :param: path: The path to the JSON to process.
    :return: A tuple containing the name/tag of the prediction target, the name of the
    model/seed that generated the results and the dictionary of results.
    Load a JSON as a dict. Return the name of the prediction target, the name of the
    model/seed that generated the results and the dictionary of results.
    """
    import json

    with open(path, "r") as f:
        scores = json.load(f)

    model = scores["model"]
    seed = scores["seed"]
    if "ptm" in scores["type"]:
        ptm = "_ptm"
    else:
        ptm = ""
    # results json filenames have the format:
    # {pymol_name}_model_{model}{""|"ptm"}_seed_{seed}_prediction_results.json
    # if we work backwards, after loading the json, we can get the pymol_name
    filename = path.split("/")[-1]
    model_seed = f"model_{model}{ptm}_seed_{seed}"
    pymol_name = filename.replace(f"_{model_seed}_prediction_results.json", "")
    return pymol_name, model_seed, scores


class SuperfoldRunner:
    """
    Class for running AF2 on any cluster with @rdkibler's Superfold.
    """

    import os
    import pwd
    import shutil
    import uuid

    import pyrosetta.distributed.io as io

    def __init__(
        self,
        pose: Union[Pose, PackedPose],
        input_file: Optional[str] = None,
        amber_relax: bool = False,
        fasta_path: Optional[str] = None,
        initial_guess: Optional[Union[bool, str]] = None,
        load_decoys: Optional[bool] = False,
        max_recycles: Optional[int] = 3,
        model_type: Optional[str] = "monomer_ptm",
        models: Optional[Union[int, List[int], List[str], str]] = "all",
        recycle_tol: Optional[float] = 0.0,
        reference_pdb: Optional[str] = None,
        simple_rmsd: Optional[bool] = True,
        save_original_pose: Optional[bool] = False,
        backfill_job_id: Optional[str] = None,
        **kwargs,
    ):
        """
        :param: pose: The pose to run Superfold on.
        :param: input_file: The path to the input file. If none, the pose will be used
        on its own.
        :param: amber_relax: Whether to run AMBER relaxation.
        :param: fasta_path: The path to the FASTA file, if any.
        :param: initial_guess: Whether to use an initial guess. If True, the pose will
        be used as an initial guess. If a string, the string will be used as the path
        to the initial guess.
        :param: load_decoys: Whether to load decoy PDBs from the results.
        :param: max_recycles: The maximum number of cycles to run Superfold.
        :param: model_type: The type of model to run.
        :param: models: The models to run.
        :param: recycle_tol: The tolerance for recycling. If the difference between
        mean plddt changes less than this value since the last recycle, the model will
        stop early.
        :param: reference_pdb: The path to the reference PDB for RMSD calculation.
        Initialize the class with the provided attributes.
        TODO in checkpoint mode, figure out how to avoid re-copying designs of runs that have already finished
        """

        import os
        from pathlib import Path

        import git

        self.pose = pose
        self.input_file = input_file
        self.amber_relax = amber_relax
        self.fasta_path = fasta_path
        self.initial_guess = initial_guess
        self.load_decoys = load_decoys
        self.max_recycles = int(max_recycles)
        self.model_type = model_type
        self.models = models
        self.recycle_tol = float(recycle_tol)
        self.simple_rmsd = simple_rmsd
        self.reference_pdb = reference_pdb
        self.save_original_pose = save_original_pose
        self.backfill_job_id = backfill_job_id
        # setup standard flags for superfold
        self.flags = {
            "--mock_msa_depth": "1",
            "--nstruct": "1",
            "--num_ensemble": "1",
            "--pct_seq_mask": "0.15",
            "--seed_start": "0",
            "--version": "monomer",
        }
        # add the flags provided by the user
        # the initial_guess flag is a special case because it is a boolean or string
        initial_guess_flag = "--initial_guess"
        if self.initial_guess is not None:
            if initial_guess == True:
                self.flags[initial_guess_flag] = " "
            else:
                self.flags[initial_guess_flag] = self.initial_guess
        else:
            pass
        # the amber_relax and reference_pdb flags are special cases as well
        if self.amber_relax:
            # store_true flag
            self.flags["--amber_relax"] = " "
        else:
            pass
        if self.simple_rmsd:
            # store_true flag
            self.flags["--simple_rmsd"] = " "
        else:
            pass
        if self.reference_pdb is not None:
            self.flags["--reference_pdb"] = self.reference_pdb
        else:
            pass
        # the models flag is a special case as well because it is either an int, a list
        # of ints, a list of strings, or a string
        if type(self.models) == int:  # convert to string
            self.flags["--models"] = str(self.models)
        elif type(self.models) == list:  # check if list of ints
            if type(self.models[0]) == int:  # convert to string
                self.flags["--models"] = " ".join(str(x) for x in self.models)
            elif type(self.models[0]) == str:  # join with space
                self.flags["--models"] = " ".join(self.models)
            else:
                raise TypeError(
                    "The models param must be either a list of ints/strings or a single int/string."
                )
        elif type(self.models) == str:  # probably good to go
            self.flags["--models"] = self.models
        else:
            raise TypeError(
                "The models param must be either a list of ints/strings or a single int/string."
            )
        self.flags.update(
            {
                "--max_recycles": str(self.max_recycles),
                "--recycle_tol": str(self.recycle_tol),
                "--type": self.model_type,
            }
        )
        # 19 total flags plus input_files
        self.allowed_flags = [
            # flags that have default values
            "--mock_msa_depth",
            "--nstruct",
            "--num_ensemble",
            "--pct_seq_mask",
            "--seed_start",
            "--version",
            # flags that are set by the constructor
            "--amber_relax",
            "--initial_guess",
            "--max_recycles",
            "--models",
            "--out_dir",
            "--recycle_tol",
            "--reference_pdb",
            "--type",
            # flags that are optional
            "--enable_dropout",
            "--simple_rmsd",
            "--output_pae",
            "--overwrite",
            "--save_intermediates",
            "--show_images",
        ]
        # use git to find the root of the repo
        repo = git.Repo(str(Path(__file__).resolve()), search_parent_directories=True)
        root = repo.git.rev_parse("--show-toplevel")
        self.python = str(Path(root) / "envs" / "shifty" / "bin" / "python")
        if os.path.exists(self.python):
            pass
        else:  # crispy env must be installed in envs/crispy or must be used on DIGS
            self.python = "/projects/crispy_shifty/envs/shifty/bin/python"
        self.script = str(
            Path(__file__).parent.parent.parent / "superfold" / "run_superfold.py"
        )
        self.tmpdir = None  # this will be updated by the setup_tmpdir method.
        self.command = None  # this will be updated by the setup_runner method.
        self.is_setup = False  # this will be updated by the setup_runner method.

    def get_command(self) -> str:
        """
        :return: command to run.
        """
        return self.command

    def get_fasta_path(self) -> str:
        """
        :return: fasta path.
        """
        return self.fasta_path

    def get_flags(self) -> Dict[str, str]:
        """
        :return: dictionary of flags.
        """
        return self.flags

    def get_script(self) -> str:
        """
        :return: script path.
        """
        return self.script

    def get_tmpdir(self) -> str:
        """
        :return: temporary directory path.
        """
        return self.tmpdir

    def override_input_file(self, input_file: str) -> None:
        """
        Override the input_file attribute.
        :param: input_file: The new input_file.
        :return: None
        """
        self.input_file = input_file
        return None

    def set_fasta_path(self, fasta_path: str) -> None:
        """
        :param: fasta_path: The path to the fasta file.
        :return: None.
        """
        self.fasta_path = fasta_path
        return None

    def set_script(self, script: str) -> None:
        """
        :param: script: The path to the script.
        :return: None.
        """
        self.script = script
        self.update_command()
        return

    def setup_tmpdir(self) -> None:
        """
        :return: None
        Create a temporary directory for the SuperfoldRunner. Checks for various best
        practice locations for the tmpdir in the following order: TMPDIR, PSCRATCH,
        CSCRATCH, /net/scratch. Uses the cwd if none of these are available.
        TODO do we need unique subdirectories for the PSCRATCH, CSCATCH, and /net/scratch 
        cases, so that things don't get overwritten during array jobs?
        """
        import os
        import pwd
        import uuid

        if self.backfill_job_id:
            # Create a tmpdir in /net/scratch with the slurm array task ID. This will persist if the job is preempted.
            # Superfold is natively backfill compatible, so when you resubmit the job, it will pick up where it left off.
            # This works as long as you resubmit the job using the same job IDs.
            self.tmpdir = os.path.join("/net/scratch", pwd.getpwuid(os.getuid()).pw_name, self.backfill_job_id, os.environ.get('SLURM_ARRAY_TASK_ID'))
        else:
            if os.environ.get("TMPDIR") is not None:
                tmpdir_root = os.environ.get("TMPDIR")
            elif os.environ.get("PSCRATCH") is not None:
                tmpdir_root = os.environ.get("PSCRATCH")
            elif os.environ.get("CSCRATCH") is not None:
                tmpdir_root = os.environ.get("CSCRATCH")
            elif os.path.exists("/net/scratch"):
                tmpdir_root = f"/net/scratch/{pwd.getpwuid(os.getuid()).pw_name}"
            else:
                tmpdir_root = os.getcwd()
            self.tmpdir = os.path.join(tmpdir_root, uuid.uuid4().hex)

        os.makedirs(self.tmpdir, exist_ok=True)
        return

    def teardown_tmpdir(self) -> None:
        """
        :return: None
        Remove the temporary directory for the SuperfoldRunner.
        """
        import shutil

        # we don't want to remove the tmpdir for backfill jobs because it will be used
        # for checkpointing any resubmitted jobs.
        if self.tmpdir is not None and self.backfill_job_id is None:
            shutil.rmtree(self.tmpdir)
        return

    def update_command(self) -> None:
        """
        :return: None
        Update the command to run.
        """
        self.command = " ".join(
            [
                f"{self.python} {self.script}",
                f"{self.input_file}",
                " ".join([f"{k} {v}" for k, v in self.flags.items()]),
            ]
        )

    def update_flags(self, update_dict: Dict[str, str]) -> None:
        """
        :param: update_dict: dictionary of flags to update.
        :return: None
        Update the flags dictionary with the provided dictionary.
        Validate the flags before updating.
        """

        for flag in update_dict.keys():
            if flag not in self.allowed_flags:
                raise ValueError(
                    f"Flag {flag} is not allowed. Allowed flags are {self.allowed_flags}"
                )
        self.flags.update(update_dict)
        return

    def setup_runner(
        self, file: Optional[str] = None, flag_update: Optional[Dict[str, str]] = None
    ) -> None:
        """
        :param: file: path to input file. If None, use the dumped tmp.pdb.
        :param: flag_update: dictionary of flags to update, if any.
        :return: None
        Setup the SuperfoldRunner.
        Create a temporary directory for the SuperfoldRunner.
        Dump the pose temporarily to a PDB file in the temporary directory.
        Update the flags dictionary with the provided dictionary if any.
        Setup the command line arguments for the SuperfoldRunner.
        """
        import json
        import os
        import sys

        import pyrosetta
        import pyrosetta.distributed.io as io
        from pyrosetta.rosetta.core.pose import clearPoseExtraScores, setPoseExtraScore

        # setup the tmpdir
        self.setup_tmpdir()
        out_path = self.tmpdir
        # avoid copying over poses to the output directory a second time if the process already completed
        if os.path.exists(os.path.join(out_path, "completed")):
            sys.exit()
        # set input_file
        if file is not None:
            self.input_file = file
        else:
            self.input_file = os.path.join(out_path, "tmp.pdb")
        # write the pose to a clean PDB file of only ATOM coordinates.
        tmp_pdb_path = os.path.join(out_path, "tmp.pdb")
        new_pose = self.pose.clone()
        clearPoseExtraScores(
            new_pose
        )  # highly important, otherwise pdbstrings in the scores get added to the pose lol
        pdbstring = io.to_pdbstring(new_pose)
        with open(tmp_pdb_path, "w") as f:
            f.write(pdbstring)
        if self.save_original_pose:
            setPoseExtraScore(self.pose, "original_pose", pdbstring)
        # update the flags with the path to the tmpdir
        self.update_flags({"--out_dir": out_path})
        if flag_update is not None:
            self.update_flags(flag_update)
        else:
            pass
        self.update_command()
        self.is_setup = True
        return

    def apply(self, pose: Pose) -> None:
        """
        :param: pose: Pose object to run Superfold on.
        :return: None
        Run Superfold on the provided pose in a subprocess.
        Read the results from the temporary directory and store them in the pose.
        Remove the temporary directory.
        """
        import json
        import os
        import sys
        from collections import defaultdict
        from glob import glob
        from pathlib import Path

        import pyrosetta
        import pyrosetta.distributed.io as io
        from pyrosetta.rosetta.core.pose import setPoseExtraScore

        # insert the root of the repo into the sys.path
        sys.path.insert(0, str(Path(__file__).resolve().parent.parent))
        from crispy_shifty.protocols.mpnn import fasta_to_dict
        from crispy_shifty.utils.io import cmd

        assert self.is_setup, "SuperfoldRunner is not setup."

        scores = dict(pose.scores)
        # run the command in a subprocess
        out_err = cmd(self.command)
        with open(os.path.join(self.tmpdir, "completed"), "w") as f:
            f.write("")
        print(out_err)
        json_files = glob(os.path.join(self.tmpdir, "*_prediction_results.json"))
        # read the json files and update a dict of dicts of dicts of scores
        # the outer dict is keyed by the pymol_name, values are all model/seed results
        # the inner dict is keyed by the model + seed, and the value is the scores dict
        results = defaultdict(dict)
        for json_file in json_files:
            pymol_name, model_seed, result = process_results_json(json_file)
            if self.load_decoys:
                if self.amber_relax:
                    suffix = "_relaxed.pdb"
                else:
                    suffix = "_unrelaxed.pdb"
                decoy_path = json_file.replace("_prediction_results.json", suffix)
                # load pose and turn it into a pdb string
                decoy_pdbstring = io.to_pdbstring(io.pose_from_file(decoy_path))
                result["decoy_pdbstring"] = decoy_pdbstring
            else:
                pass
            results[pymol_name].update({model_seed: result})
        # turn results back into a regular dict
        results = dict(results)
        # check if there were already sequences in the pose datacache
        seqs = {k: {"seq": v} for k, v in scores.items() if k in results.keys()}
        # check if a fasta was provided
        if self.fasta_path is not None:
            # check if the fasta is the same as the input file
            if self.fasta_path == self.input_file:
                # if so, make a dict of the sequences in the fasta
                tag_seq_dict = fasta_to_dict(self.fasta_path)
                # and nest the sequences in that dict
                tag_seq_dict = {k: {"seq": v} for k, v in tag_seq_dict.items()}
            else:
                raise NotImplementedError(
                    "Fasta path is not the same as the input file."
                )

            if len(seqs) > 0:  # check that the seqs dict matches the fasta dict
                if seqs == tag_seq_dict:
                    pass
                else:
                    seqs = tag_seq_dict  # we want the seqs we did predictions on
            else:
                seqs = tag_seq_dict  # we want the seqs we did predictions on

        elif len(seqs) == 0 and len(results) == 1:
            # then this was a single sequence run
            seqs = {"tmp": {"seq": pose.sequence()}}

        else:
            raise NotImplementedError("I am not sure how this behaves with silents")

        # update the results with the sequences and update the pose with those results
        for tag, result in results.items():
            result.update(seqs[tag])
            setPoseExtraScore(pose, tag, json.dumps(result))
        # clean up the temporary files
        self.teardown_tmpdir()
        return


class SuperfoldMultiPDB(SuperfoldRunner):
    """
    SuperfoldRunner for multiple PDB files.
    """

    import os
    import pwd
    import shutil
    import uuid

    import pyrosetta.distributed.io as io

    def __init__(
        self,
        *args,
        **kwargs,
    ):
        """
        :param: args: arguments to SuperfoldRunner.
        :param: kwargs: keyword arguments to SuperfoldRunner.
        :return: None
        Initialize the the base class for Superfold runners with common attributes.
        """

        from pyrosetta.rosetta.core.pose import Pose

        dummy_pose = Pose()
        # pass a dummy pose to the superclass

        super().__init__(*args, pose=dummy_pose, **kwargs)
        self.tag_pose_dict = {}

    def setup_runner(
        self,
        chains_to_keep: Optional[List[int]] = None,
        flag_update: Optional[Dict[str, str]] = None,
        cluster_scores: Optional[Union[str, bool]] = True
    ) -> None:
        """
        :param: chains_to_keep: list of chains to keep in the pose. If None, keep all
        chains. Must be a list of ints.
        :param: flag_update: dictionary of flags to update, if any.
        :return: None
        Setup the SuperfoldMultiPDB.
        Create a temporary directory for the SuperfoldMultiPDB.
        Make a dict of the poses and their tags.
        Dump the poses temporarily to PDB files in the temporary directory.
        Dump the pose temporarily to a PDB file in the temporary directory.
        Update the flags dictionary with the provided dictionary if any.
        Setup the command line arguments for the SuperfoldRunner.
        """
        import json
        import os
        import sys
        from glob import glob
        from pathlib import Path

        import pyrosetta
        import pyrosetta.distributed.io as io
        from pyrosetta.rosetta.core.pose import clearPoseExtraScores, setPoseExtraScore

        # insert the root of the repo into the sys.path
        sys.path.insert(0, str(Path(__file__).resolve().parent.parent))
        from crispy_shifty.protocols.cleaning import path_to_pose_or_ppose

        # setup the tmpdir
        self.setup_tmpdir()
        out_path = self.tmpdir
        # avoid copying over poses to the output directory a second time if the process already completed
        if os.path.exists(os.path.join(out_path, "completed")):
            sys.exit()
        # check that input_file was provided
        if not self.tag_pose_dict:
            if self.input_file is None:
                raise ValueError("No input file provided.")
            else:
                pass
            # read in the input files as poses and store them in a dict
            for path in self.input_file.split():
                # the following is a bit unsafe to get rid of the extension
                # TODO use pathlib
                tag = os.path.basename(path).split(".pdb")[0]
                self.tag_pose_dict[tag] = next(
                    path_to_pose_or_ppose(
                        path=path, cluster_scores=cluster_scores, pack_result=False
                    )
                )
        # write the poses to clean PDB files of only ATOM coordinates.
        pdb_files = []
        for tag, pose in self.tag_pose_dict.items():
            if self.save_original_pose:
                new_pose = pose.clone()
                clearPoseExtraScores(
                    new_pose
                )  # highly important, otherwise pdbstrings in the scores get added to the pose lol
                setPoseExtraScore(pose, "original_pose", io.to_pdbstring(new_pose))
            tmp_pdb_path = os.path.join(out_path, f"{tag}.pdb")
            if chains_to_keep is not None:
                # get the chains to keep
                chains_list = list(pose.split_by_chain())
                new_pose = Pose()
                for i, chain in enumerate(chains_list, start=1):
                    if i in chains_to_keep:
                        pyrosetta.rosetta.core.pose.append_pose_to_pose(
                            new_pose, chain, new_chain=True
                        )
                    else:
                        pass
                pdbstring = io.to_pdbstring(new_pose)
            else:
                new_pose = pose.clone()
                clearPoseExtraScores(new_pose)
                pdbstring = io.to_pdbstring(new_pose)
            with open(tmp_pdb_path, "w") as f:
                f.write(pdbstring)
            pdb_files.append(tmp_pdb_path)
        # update the input file to point to this list of PDB files
        self.input_file = " ".join(pdb_files)
        # update the flags with the path to the tmpdir
        self.update_flags({"--out_dir": out_path})
        if flag_update is not None:
            self.update_flags(flag_update)
        else:
            pass
        self.update_command()
        self.is_setup = True
        return

    def apply(self) -> None:
        """
        :return: None
        Run Superfold on the input files.
        Read the results from the temporary directory and store them in the poses.
        Remove the temporary directory.
        """
        import json
        import os
        import sys
        from collections import defaultdict
        from glob import glob
        from pathlib import Path

        import pyrosetta
        import pyrosetta.distributed.io as io
        from pyrosetta.rosetta.core.pose import setPoseExtraScore

        # insert the root of the repo into the sys.path
        sys.path.insert(0, str(Path(__file__).resolve().parent.parent))
        from crispy_shifty.protocols.mpnn import fasta_to_dict
        from crispy_shifty.utils.io import cmd

        assert self.is_setup, "SuperfoldRunner is not setup."

        # run the command in a subprocess
        out_err = cmd(self.command)
        with open(os.path.join(self.tmpdir, "completed"), "w") as f:
            f.write("")
        print(out_err)
        json_files = glob(os.path.join(self.tmpdir, "*_prediction_results.json"))
        # read the json files and update a dict of dicts of dicts of scores
        # the outer dict is keyed by the pymol_name, values are all model/seed results
        # the inner dict is keyed by the model and seed, and the value is the scores
        results = defaultdict(dict)
        for json_file in json_files:
            pymol_name, model_seed, result = process_results_json(json_file)
            if self.load_decoys:
                if self.amber_relax:
                    suffix = "_relaxed.pdb"
                else:
                    suffix = "_unrelaxed.pdb"
                decoy_path = json_file.replace("_prediction_results.json", suffix)
                # load pose and turn it into a pdb string
                decoy_pdbstring = io.to_pdbstring(io.pose_from_file(decoy_path))
                result["decoy_pdbstring"] = decoy_pdbstring
            else:
                pass
            results[pymol_name].update({model_seed: result})
        # turn results back into a regular dict
        results = dict(results)
        # now put the results in the poses
        for tag, pose in self.tag_pose_dict.items():
            # get the scores from the pose
            scores = dict(pose.scores)
            # get the results for this tag
            result = results[tag]
            # update the result with the sequence and update the pose with the results
            result.update({"seq": pose.sequence()})
            setPoseExtraScore(pose, tag, json.dumps(result))
        # clean up the temporary files
        self.teardown_tmpdir()
        return

    def get_tag_pose_dict(self) -> Dict[str, Pose]:
        """
        :return: dict of the poses and their tags
        """
        return self.tag_pose_dict


@requires_init
def fold_bound_state(
    packed_pose_in: Optional[PackedPose] = None, **kwargs
) -> Iterator[PackedPose]:
    """
    :param: packed_pose_in: a PackedPose object to fold with the superfold script.
    :param: kwargs: keyword arguments to be passed to the superfold script.
    :return: an iterator of PackedPose objects.
    """

    import sys
    from operator import gt, lt
    from pathlib import Path
    from time import time

    import pyrosetta
    import pyrosetta.distributed.io as io

    # insert the root of the repo into the sys.path
    sys.path.insert(0, str(Path(__file__).resolve().parent.parent))
    from crispy_shifty.protocols.cleaning import path_to_pose_or_ppose
    from crispy_shifty.utils.io import cmd, print_timestamp

    start_time = time()
    # hacky split pdb_path into pdb_path and fasta_path
    pdb_path = kwargs.pop("pdb_path")
    pdb_path, fasta_path = tuple(pdb_path.split("____"))

    # set up prefix, rank_on, filter_dict (in this case we can't get from kwargs)
    rank_on = kwargs.pop("rank_on", "mean_plddt")

    if "filter_str" in kwargs.keys():
        filter_str = kwargs.pop("filter_str")
        if filter_str=="no_filter":
            filter_dict={}
        else:
            op_dict = {"gt": gt, "lt": lt}
            filter_dict={item.split(',')[0]:(op_dict[item.split(',')[1]],float(item.split(',')[2])) for item in filter_str.split(":")}
    else:
        filter_dict = {
            "mean_plddt": (gt, 92.0),
            "rmsd_to_reference": (lt, 1.5),
            "mean_pae_interaction": (lt, 5),
        }

    # generate poses or convert input packed pose into pose
    if packed_pose_in is not None:
        poses = [io.to_pose(packed_pose_in)]
        pdb_path = "none"
    else:
        # skip the kwargs check
        poses = path_to_pose_or_ppose(
            path=pdb_path, cluster_scores=True, pack_result=False
        )
    gen_decoys_kwargs={}
    gen_decoys=False
    if "generate_prediction_decoys" in kwargs.keys():
        if kwargs["generate_prediction_decoys"].lower() == "true":
            gen_decoys_kwargs["generate_prediction_decoys"]=True
            gen_decoys=True
    for pose in poses:
        pose.update_residue_neighbors()
        scores = dict(pose.scores)
        print_timestamp("Setting up for AF2", start_time)
        if gen_decoys:
            runner = SuperfoldRunner(pose=pose, fasta_path=fasta_path, load_decoys=True, **kwargs)
        else:
            runner = SuperfoldRunner(pose=pose, fasta_path=fasta_path, **kwargs)
        runner.setup_runner(file=fasta_path)
        # initial_guess, reference_pdb both are the tmp.pdb
        initial_guess = str(Path(runner.get_tmpdir()) / "tmp.pdb")
        reference_pdb = initial_guess
        flag_update = {"--reference_pdb": reference_pdb}
        if "use_initial_guess" in kwargs:
            if not kwargs["use_initial_guess"].lower() == "false":
                flag_update["--initial_guess"] = initial_guess
        else:
            flag_update["--initial_guess"] = initial_guess
        runner.update_flags(flag_update)
        runner.update_command()
        print_timestamp("Running AF2", start_time)
        runner.apply(pose)
        print_timestamp("AF2 complete, updating pose datacache", start_time)
        # update the scores dict
        scores.update(pose.scores)
        # update the pose with the updated scores dict
        for key, value in scores.items():
            pyrosetta.rosetta.core.pose.setPoseExtraScore(pose, key, value)
        rank_on = "mean_plddt"
        prefix = "mpnn_seq"
        for decoy in generate_decoys_from_pose(
            pose,
            filter_dict=filter_dict,
            label_first=True,
            prefix=prefix,
            rank_on=rank_on,
            **gen_decoys_kwargs
        ):
            packed_decoy = io.to_packed(decoy)
            yield packed_decoy


@requires_init
def fold_paired_state_Y(
    packed_pose_in: Optional[PackedPose] = None, **kwargs
) -> Iterator[PackedPose]:
    """
    :param: packed_pose_in: a PackedPose object to fold with the superfold script.
    :param: kwargs: keyword arguments to be passed to the superfold script.
    :return: an iterator of PackedPose objects.
    """

    import sys
    from operator import gt, lt
    from pathlib import Path
    from time import time

    import pyrosetta
    import pyrosetta.distributed.io as io
    from pyrosetta.rosetta.core.pose import Pose

    # insert the root of the repo into the sys.path
    sys.path.insert(0, str(Path(__file__).resolve().parent.parent))
    from crispy_shifty.protocols.cleaning import path_to_pose_or_ppose
    from crispy_shifty.protocols.mpnn import dict_to_fasta, fasta_to_dict
    from crispy_shifty.utils.io import cmd, print_timestamp

    start_time = time()
    # hacky split pdb_path into pdb_path and fasta_path
    pdb_path = kwargs.pop("pdb_path")
    pdb_path, fasta_path = tuple(pdb_path.split("____"))

    clean_disulfides = False
    if "clean_disulfides" in kwargs:
        if kwargs.pop("clean_disulfides").lower() == "true":
            clean_disulfides = True

    if "filter_str" in kwargs.keys():
        filter_str = kwargs.pop("filter_str")
        if filter_str=="no_filter":
            filter_dict={}
        else:
            op_dict = {"gt": gt, "lt": lt}
            filter_dict={item.split(',')[0]:(op_dict[item.split(',')[1]],float(item.split(',')[2])) for item in filter_str.split(":")}
    else:
        filter_dict = {
            "mean_plddt": (gt, 93.0),
            "rmsd_to_reference": (lt, 1.5),
            "mean_pae_interaction": (lt, 5),
        }

    # generate poses or convert input packed pose into pose
    if packed_pose_in is not None:
        poses = [io.to_pose(packed_pose_in)]
        pdb_path = "none"
    else:
        # skip the kwargs check
        poses = path_to_pose_or_ppose(
            path=pdb_path, cluster_scores=True, pack_result=False
        )

    for pose in poses:
        pose.update_residue_neighbors()
        scores = dict(pose.scores)
        # load fasta into a dict
        tmp_fasta_dict = fasta_to_dict(fasta_path)
        pose_chains = list(pose.split_by_chain())
        # slice out the bound state, aka chains A and B
        tmp_pose = Pose()
        pyrosetta.rosetta.core.pose.append_pose_to_pose(
            tmp_pose, pose_chains[0], new_chain=True
        )
        pyrosetta.rosetta.core.pose.append_pose_to_pose(
            tmp_pose, pose_chains[1], new_chain=True
        )
        # fix the fasta by splitting on chainbreaks '/' and rejoining the first two
        tmp_fasta_dict = {
            tag: "/".join(seq.split("/")[0:2]) for tag, seq in tmp_fasta_dict.items()
        }
        # change the pose to the modified pose
        pose = tmp_pose.clone()
        print_timestamp("Setting up for AF2", start_time)
        runner = SuperfoldRunner(
            pose=pose, fasta_path=fasta_path, load_decoys=True, **kwargs
        )
        runner.setup_runner(file=fasta_path)
        # initial_guess, reference_pdb both are the tmp.pdb
        initial_guess = str(Path(runner.get_tmpdir()) / "tmp.pdb")
        reference_pdb = initial_guess
        flag_update = {
            "--initial_guess": initial_guess,
            "--reference_pdb": reference_pdb,
        }
        # now we have to point to the right fasta file
        new_fasta_path = str(Path(runner.get_tmpdir()) / "tmp.fa")
        dict_to_fasta(tmp_fasta_dict, new_fasta_path)
        runner.set_fasta_path(new_fasta_path)
        runner.override_input_file(new_fasta_path)
        runner.update_flags(flag_update)
        runner.update_command()
        print_timestamp("Running AF2", start_time)
        runner.apply(pose)
        print_timestamp("AF2 complete, updating pose datacache", start_time)
        # update the scores dict
        scores.update(pose.scores)
        # update the pose with the updated scores dict
        for key, value in scores.items():
            pyrosetta.rosetta.core.pose.setPoseExtraScore(pose, key, value)
        rank_on = "mean_plddt"
        prefix = "mpnn_seq"
        print_timestamp("Generating decoys", start_time)
        for decoy in generate_decoys_from_pose(
            pose,
            filter_dict=filter_dict,
            generate_prediction_decoys=True,
            label_first=True,
            prefix=prefix,
            rank_on=rank_on,
        ):
            # add the free state back into the decoy
            for other_chain in pose_chains[2:]:
                pyrosetta.rosetta.core.pose.append_pose_to_pose(
                    decoy, other_chain, new_chain=True
                )

            # clean ostensibly disulfide-bonded cysteines individually because they have unspecified partners
            if clean_disulfides:
                seq = decoy.sequence()
                all_cys_resi_indexes = [
                    i for i, r in enumerate(seq, start=1) if r == "C"
                ]
                for i in all_cys_resi_indexes:
                    if decoy.conformation().residue(i).type().is_disulfide_bonded():
                        pyrosetta.rosetta.core.conformation.change_cys_state(
                            i, "", decoy.conformation()
                        )

            # get the chA sequence
            chA_seq = decoy.chain_sequence(
                1
            )  # list(decoy.split_by_chain())[0].sequence()
            # setup SimpleThreadingMover
            stm = pyrosetta.rosetta.protocols.simple_moves.SimpleThreadingMover()
            # thread the sequence from chA onto chA
            stm.set_sequence(chA_seq, start_position=decoy.chain_begin(3))
            stm.apply(decoy)
            # rename af2 metrics to have Y_ prefix
            decoy_scores = dict(decoy.scores)
            for key, value in decoy_scores.items():
                if key in af2_metrics:
                    pyrosetta.rosetta.core.pose.setPoseExtraScore(
                        decoy, f"Y_{key}", value
                    )

            packed_decoy = io.to_packed(decoy)
            yield packed_decoy


@requires_init
def fold_paired_state_X(
    packed_pose_in: Optional[PackedPose] = None, **kwargs
) -> Iterator[PackedPose]:
    """
    :param: packed_pose_in: a PackedPose object to fold with the Superfold script.
    :param: kwargs: keyword arguments to be passed to the Superfold script.
    :return: an iterator of PackedPose objects.
    """

    import os
    import sys
    from pathlib import Path
    from time import time

    import pyrosetta
    import pyrosetta.distributed.io as io
    from pyrosetta.rosetta.core.pose import Pose

    # insert the root of the repo into the sys.path
    sys.path.insert(0, str(Path(__file__).resolve().parent.parent))
    from crispy_shifty.protocols.cleaning import path_to_pose_or_ppose
    from crispy_shifty.protocols.mpnn import dict_to_fasta, fasta_to_dict
    from crispy_shifty.protocols.states import range_CA_align
    from crispy_shifty.utils.io import cmd, print_timestamp

    start_time = time()
    # get the pdb_path from the kwargs
    pdb_path = kwargs.pop("pdb_path")
    # there are multiple paths in the pdb_path, we need to split them and rejoin them
    pdb_paths = pdb_path.split("____")
    pdb_path = " ".join(pdb_paths)

    # this function is special, we don't want a packed_pose_in ever, we maintain it as
    # a kwarg for backward compatibility with PyRosettaCluster
    if packed_pose_in is not None:
        raise ValueError("This function is not intended to have a packed_pose_in")
    else:
        pass

    print_timestamp("Setting up for AF2", start_time)
    runner = SuperfoldMultiPDB(input_file=pdb_path, load_decoys=True, **kwargs)
    runner.setup_runner(chains_to_keep=[3])
    print_timestamp("Running AF2", start_time)
    runner.apply()
    print_timestamp("AF2 complete, updating pose datacache", start_time)
    # get the updated poses from the runner
    tag_pose_dict = runner.get_tag_pose_dict()
    # filter the decoys
    if "filter_str" in kwargs.keys():
        filter_str = kwargs.pop("filter_str")
        if filter_str=="no_filter":
            filter_dict={}
        else:
            op_dict = {"gt": gt, "lt": lt}
            filter_dict={item.split(',')[0]:(op_dict[item.split(',')[1]],float(item.split(',')[2])) for item in filter_str.split(":")}
    else:
        filter_dict = {
            "mean_plddt": (gt, 93.0),
            "rmsd_to_reference": (lt, 1.5),
        }
    rank_on = "mean_plddt"
    print_timestamp("Generating decoys", start_time)
    sw = pyrosetta.rosetta.protocols.simple_moves.SwitchChainOrderMover()
    for tag, pose in tag_pose_dict.items():
        for decoy in generate_decoys_from_pose(
            pose,
            filter_dict=filter_dict,
            generate_prediction_decoys=True,
            label_first=False,
            prefix=tag,
            rank_on=rank_on,
        ):
            scores = dict(decoy.scores)
            bound_pose = None
            for original_path in pdb_paths:
                if tag in original_path:
                    bound_pose = next(
                        path_to_pose_or_ppose(
                            path=original_path, cluster_scores=True, pack_result=False
                        )
                    )
                    final_pose = Pose()
                    # get the first two chains from the input
                    bound_split = list(bound_pose.split_by_chain())
                    for chain in bound_split[:2]:
                        pyrosetta.rosetta.core.pose.append_pose_to_pose(
                            final_pose, chain, new_chain=True
                        )
                    # yeet decoy
                    # aligning rather than yeeting keeps state X in the correct orientation relative to other stuff that might be in the pose
                    range_CA_align(
                        decoy, bound_split[2], 1, decoy.size(), 1, bound_split[2].size()
                    )
                    pyrosetta.rosetta.core.pose.append_pose_to_pose(
                        final_pose, decoy, new_chain=True
                    )
                    if len(bound_split) > 3:
                        for chain in bound_split[3:]:
                            pyrosetta.rosetta.core.pose.append_pose_to_pose(
                                final_pose, chain, new_chain=True
                            )
                    sw.chain_order(
                        "".join(str(i + 1) for i in range(bound_pose.num_chains()))
                    )
                    sw.apply(final_pose)
                    break
                else:
                    continue
            if bound_pose is None:
                raise RuntimeError
            else:
                pass
            for key, value in scores.items():
                pyrosetta.rosetta.core.pose.setPoseExtraScore(final_pose, key, value)
            final_ppose = io.to_packed(final_pose)
            yield final_ppose


@requires_init
def fold_paired_state_all(
    packed_pose_in: Optional[PackedPose] = None, **kwargs
) -> Iterator[PackedPose]:
    """
    :param: packed_pose_in: a PackedPose object to fold with the Superfold script.
    :param: kwargs: keyword arguments to be passed to the Superfold script.
    :return: an iterator of PackedPose objects.
    """

    import os
    import sys
    from pathlib import Path
    from time import time

    import pyrosetta
    import pyrosetta.distributed.io as io
    from pyrosetta.rosetta.core.pose import Pose
    from pyrosetta.rosetta.core.select.residue_selector import ChainSelector

    # insert the root of the repo into the sys.path
    sys.path.insert(0, str(Path(__file__).resolve().parent.parent))
    from crispy_shifty.protocols.alignment import score_rmsd
    from crispy_shifty.protocols.states import range_CA_align
    from crispy_shifty.utils.io import print_timestamp

    start_time = time()
    # get the pdb_path from the kwargs
    pdb_path = kwargs.pop("pdb_path")
    # there are multiple paths in the pdb_path, we need to split them and rejoin them
    pdb_paths = pdb_path.split("____")
    pdb_path = " ".join(pdb_paths)

    # this function is special, we don't want a packed_pose_in ever, we maintain it as
    # a kwarg for backward compatibility with PyRosettaCluster
    if packed_pose_in is not None:
        raise ValueError("This function is not intended to have a packed_pose_in")
    else:
        pass

    print_timestamp("Setting up for AF2 state Y", start_time)
    runner = SuperfoldMultiPDB(
        input_file=pdb_path,
        load_decoys=True,
        save_original_pose=True,
        initial_guess=True,
        **kwargs,
    )
    runner.setup_runner(chains_to_keep=[1, 2])
    print_timestamp("Running AF2", start_time)
    runner.apply()
    print_timestamp("AF2 complete, updating pose datacache", start_time)
    # get the updated poses from the runner
    tag_pose_dict = runner.get_tag_pose_dict()
    # don't filter the decoys
    if "filter_str" in kwargs.keys():
        filter_str = kwargs.pop("filter_str")
        if filter_str=="no_filter":
            filter_dict={}
        else:
            op_dict = {"gt": gt, "lt": lt}
            filter_dict={item.split(',')[0]:(op_dict[item.split(',')[1]],float(item.split(',')[2])) for item in filter_str.split(":")}
    else:
        filter_dict = {}
    # would rank on mean_plddt but this could create a situation where the best plddt model is folded into the incorrect state
    rank_on = "rmsd_to_input"
    print_timestamp("Generating decoys", start_time)
    sw = pyrosetta.rosetta.protocols.simple_moves.SwitchChainOrderMover()
    for tag, pose in tag_pose_dict.items():
        for decoy in generate_decoys_from_pose(
            pose,
            filter_dict=filter_dict,
            generate_prediction_decoys=True,
            label_first=False,
            prefix=tag,
            rank_on=rank_on,
            add_alt_model_scores=True,
        ):
            scores = dict(decoy.scores)
            original_pose = io.to_pose(io.pose_from_pdbstring(scores["original_pose"]))
            out_pose = Pose()
            for chain in list(decoy.split_by_chain()):
                pyrosetta.rosetta.core.pose.append_pose_to_pose(
                    out_pose, chain, new_chain=True
                )
            # get the rest of the chains from the input
            original_split = list(original_pose.split_by_chain())
            for chain in original_split[2:]:
                pyrosetta.rosetta.core.pose.append_pose_to_pose(
                    out_pose, chain, new_chain=True
                )
            sw.chain_order("".join(str(i + 1) for i in range(len(original_split))))
            sw.apply(out_pose)
            for key, value in scores.items():
                # rename af2 metrics to have Y_ prefix
                if ("model_" in key and "_seed_" in key) or key in af2_metrics:
                    pyrosetta.rosetta.core.pose.setPoseExtraScore(
                        out_pose, f"Y_{key}", value
                    )
                else:
                    pyrosetta.rosetta.core.pose.setPoseExtraScore(out_pose, key, value)
            tag_pose_dict[tag] = out_pose

    print_timestamp("Setting up for AF2 state X", start_time)
    runner = SuperfoldMultiPDB(load_decoys=True, save_original_pose=True, **kwargs)
    runner.tag_pose_dict = tag_pose_dict
    runner.setup_runner(chains_to_keep=[3])
    print_timestamp("Running AF2", start_time)
    runner.apply()
    print_timestamp("AF2 complete, updating pose datacache", start_time)
    # get the updated poses from the runner
    tag_pose_dict = runner.get_tag_pose_dict()
    # don't filter the decoys
    print_timestamp("Generating decoys", start_time)
    for tag, pose in tag_pose_dict.items():
        for decoy in generate_decoys_from_pose(
            pose,
            filter_dict=filter_dict,
            generate_prediction_decoys=True,
            label_first=False,
            prefix=tag,
            rank_on=rank_on,
            add_alt_model_scores=True,
        ):
            scores = dict(decoy.scores)
            original_pose = io.to_pose(
                io.pose_from_pdbstring(scores.pop("original_pose"))
            )
            out_pose = Pose()
            # get the rest of the chains from the input
            original_split = list(original_pose.split_by_chain())
            for chain in original_split[:2]:
                pyrosetta.rosetta.core.pose.append_pose_to_pose(
                    out_pose, chain, new_chain=True
                )
            # yeet decoy
            # aligning rather than yeeting keeps state X in the correct orientation relative to other stuff that might be in the pose
            range_CA_align(
                decoy, original_split[2], 1, decoy.size(), 1, original_split[2].size()
            )
            pyrosetta.rosetta.core.pose.append_pose_to_pose(
                out_pose, decoy, new_chain=True
            )
            if len(original_split) > 3:
                for chain in original_split[3:]:
                    pyrosetta.rosetta.core.pose.append_pose_to_pose(
                        out_pose, chain, new_chain=True
                    )
            sw.chain_order("".join(str(i + 1) for i in range(len(original_split))))
            sw.apply(out_pose)
            Y_sel = ChainSelector("A")
            X_sel = ChainSelector("C")
            for key, value in scores.items():
                if "decoy_pdbstring" in key:
                    # calculate hinge RMSD to the alternate conformation
                    alt_pose = io.to_pose(io.pose_from_pdbstring(value))
                    if "Y_" in key:
                        score_name = key.split("__")[0] + "__rmsd_to_X"
                        # need refsel because Y alt_poses have two chains; I only want the rmsd of the hinge
                        score_rmsd(
                            out_pose, alt_pose, sel=X_sel, refsel=Y_sel, name=score_name
                        )
                    else:
                        score_name = "X_" + key.split("__")[0] + "__rmsd_to_Y"
                        score_rmsd(out_pose, alt_pose, sel=Y_sel, name=score_name)
                # rename af2 metrics to have X_ prefix
                # change this to an if if you want to save pdbstrings in the scores
                # doing so makes it annoying to load the score files and to load the pdbs in pymol and rosetta later
                elif (("model_" in key and "_seed_" in key) or key in af2_metrics) and (
                    "Y_" not in key
                ):
                    pyrosetta.rosetta.core.pose.setPoseExtraScore(
                        out_pose, f"X_{key}", value
                    )
                else:
                    pyrosetta.rosetta.core.pose.setPoseExtraScore(out_pose, key, value)

            final_ppose = io.to_packed(out_pose)
            yield final_ppose


@requires_init
def fold_general(
    packed_pose_in: Optional[PackedPose] = None, **kwargs
) -> Iterator[PackedPose]:
    """
    :param: packed_pose_in: a PackedPose object to fold with the Superfold script.
    :param: kwargs: keyword arguments to be passed to the Superfold script.
    :return: an iterator of PackedPose objects.
    """

    import sys
    from pathlib import Path
    from time import time

    import pyrosetta
    import pyrosetta.distributed.io as io

    # insert the root of the repo into the sys.path
    sys.path.insert(0, str(Path(__file__).resolve().parent.parent))
    from crispy_shifty.protocols.alignment import score_rmsd
    from crispy_shifty.protocols.cleaning import path_to_pose_or_ppose
    from crispy_shifty.protocols.design import score_SAP
    from crispy_shifty.utils.io import print_timestamp

    start_time = time()
    # get the pdb_path from the kwargs
    pdb_path = kwargs.pop("pdb_path")
    cluster_scores = kwargs.pop("df_scores", True)
    chain_order_str = kwargs.pop("chains_to_fold", False)
    rank_on = kwargs.pop("rank_on", False)
    if kwargs.pop("use_initial_guess", "").lower() == "true":
        initial_guess = True
    else:
        initial_guess = None
    score_prefix = kwargs.pop("score_prefix", "")

    # generate poses or convert input packed pose into pose
    if packed_pose_in is not None:
        poses = [io.to_pose(packed_pose_in)]
        pdb_path = "none"
    else:
        # skip the kwargs check
        poses = path_to_pose_or_ppose(
            path=pdb_path, cluster_scores=cluster_scores, pack_result=False
        )

    if chain_order_str:
        sw = pyrosetta.rosetta.protocols.simple_moves.SwitchChainOrderMover()
        sw.chain_order(chain_order_str)

    for pose in poses:
        pose.update_residue_neighbors()
        scores = dict(pose.scores)

        if chain_order_str:
            sw.apply(pose)
        
        print_timestamp("Setting up for AF2", start_time)
        runner = SuperfoldRunner(
            pose=pose,
            load_decoys=True,
            simple_rmsd=True,
            initial_guess=initial_guess,
            **kwargs,
        )
        runner.setup_runner()
        runner.update_command()
        print_timestamp("Running AF2", start_time)
        runner.apply(pose)
        print_timestamp("AF2 complete, updating pose datacache", start_time)
        # update the scores dict
        scores.update(pose.scores)
        # update the pose with the updated scores dict
        for key, value in scores.items():
            pyrosetta.rosetta.core.pose.setPoseExtraScore(pose, key, value)
        # setup prefix, rank_on, filter_dict (in this case we can't get from kwargs)
        print_timestamp("Generating decoys", start_time)
        for i, decoy in enumerate(generate_decoys_from_pose(
            pose,
            filter_dict={},
            generate_prediction_decoys=True,
            label_first=False,
            prefix="tmp",
            rank_on=rank_on,
        )):
            if i == 0:
                best_decoy = decoy.clone()
            decoy_scores = dict(decoy.scores)
            for key, value in decoy_scores.items():
                if key in af2_metrics:
                    pyrosetta.rosetta.core.pose.setPoseExtraScore(
                        decoy, score_prefix + key, value
                    )
                else:
                    pyrosetta.rosetta.core.pose.setPoseExtraScore(decoy, key, value)
            
            score_SAP(decoy, score_prefix + "SAP")
            score_rmsd(decoy, best_decoy, name=score_prefix + "rmsd_to_best")

            packed_decoy = io.to_packed(decoy)
            yield packed_decoy


@requires_init
def fold_general_multi_pdb(
    packed_pose_in: Optional[PackedPose] = None, **kwargs
) -> Iterator[PackedPose]:
    """
    :param: packed_pose_in: a PackedPose object to fold with the Superfold script.
    :param: kwargs: keyword arguments to be passed to the Superfold script.
    :return: an iterator of PackedPose objects.
    """

    import sys
    from pathlib import Path
    from time import time

    import pyrosetta
    import pyrosetta.distributed.io as io

    # insert the root of the repo into the sys.path
    sys.path.insert(0, str(Path(__file__).resolve().parent.parent))
    from crispy_shifty.protocols.alignment import score_rmsd
    from crispy_shifty.protocols.design import score_SAP
    from crispy_shifty.utils.io import print_timestamp

    start_time = time()
    # get the pdb_path from the kwargs
    pdb_path = kwargs.pop("pdb_path")
    # there are multiple paths in the pdb_path, we need to split them and rejoin them
    pdb_paths = pdb_path.split("____")
    pdb_path = " ".join(pdb_paths)

    # this function is special, we don't want a packed_pose_in ever, we maintain it as
    # a kwarg for backward compatibility with PyRosettaCluster
    if packed_pose_in is not None:
        raise ValueError("This function is not intended to have a packed_pose_in")
    else:
        pass

    cluster_scores = kwargs.pop("df_scores", True)
    chains_to_fold = kwargs.pop("chains_to_fold", None)
    if type(chains_to_fold) == str:
        chains_to_fold = [int(c) for c in chains_to_fold]
    rank_on = kwargs.pop("rank_on", False)
    if kwargs.pop("use_initial_guess", "").lower() == "true":
        initial_guess = True
    else:
        initial_guess = None
    score_prefix = kwargs.pop("score_prefix", "")
        
    print_timestamp("Setting up for AF2", start_time)
    runner = SuperfoldMultiPDB(input_file=pdb_path, load_decoys=True, simple_rmsd=True, initial_guess=initial_guess, **kwargs)
    runner.setup_runner(chains_to_keep=chains_to_fold, cluster_scores=cluster_scores)
    print_timestamp("Running AF2", start_time)
    runner.apply()
    print_timestamp("AF2 complete, updating pose datacache", start_time)
    tag_pose_dict = runner.get_tag_pose_dict()
    for tag, pose in tag_pose_dict.items():
        print_timestamp("Generating decoys", start_time)
        for i, decoy in enumerate(generate_decoys_from_pose(
            pose,
            filter_dict={},
            generate_prediction_decoys=True,
            label_first=False,
            prefix=tag,
            rank_on=rank_on,
        )):
            if i == 0:
                best_decoy = decoy.clone()
            decoy_scores = dict(decoy.scores)
            for key, value in decoy_scores.items():
                if key in af2_metrics:
                    pyrosetta.rosetta.core.pose.setPoseExtraScore(
                        decoy, score_prefix + key, value
                    )
                else:
                    pyrosetta.rosetta.core.pose.setPoseExtraScore(decoy, key, value)
            
            score_SAP(decoy, score_prefix + "SAP")
            score_rmsd(decoy, best_decoy, name=score_prefix + "rmsd_to_best")

            packed_decoy = io.to_packed(decoy)
            yield packed_decoy


@requires_init
def fold_paired_state_Y_preserve_bfactors(
    packed_pose_in: Optional[PackedPose] = None, **kwargs
) -> Iterator[PackedPose]:
    """
    :param: packed_pose_in: a PackedPose object to fold with the superfold script.
    :param: kwargs: keyword arguments to be passed to the superfold script.
    :return: an iterator of PackedPose objects.
    """

    import sys
    from operator import gt, lt
    from pathlib import Path
    from time import time

    import pyrosetta
    import pyrosetta.distributed.io as io
    from pyrosetta.rosetta.core.pose import Pose

    # insert the root of the repo into the sys.path
    sys.path.insert(0, str(Path(__file__).resolve().parent.parent))
    from crispy_shifty.protocols.cleaning import path_to_pose_or_ppose
    from crispy_shifty.protocols.mpnn import dict_to_fasta, fasta_to_dict
    from crispy_shifty.utils.io import cmd, print_timestamp

    start_time = time()
    # hacky split pdb_path into pdb_path and fasta_path
    pdb_path = kwargs.pop("pdb_path")
    pdb_path, fasta_path = tuple(pdb_path.split("____"))

    clean_disulfides = False
    if "clean_disulfides" in kwargs:
        if kwargs.pop("clean_disulfides").lower() == "true":
            clean_disulfides = True

    # generate poses or convert input packed pose into pose
    if packed_pose_in is not None:
        poses = [io.to_pose(packed_pose_in)]
        pdb_path = "none"
    else:
        # skip the kwargs check
        poses = path_to_pose_or_ppose(
            path=pdb_path, cluster_scores=True, pack_result=False
        )

    for pose in poses:
        pose.update_residue_neighbors()
        scores = dict(pose.scores)
        # load fasta into a dict
        tmp_fasta_dict = fasta_to_dict(fasta_path)
        pose_chains = list(pose.split_by_chain())
        # slice out the bound state, aka chains A and B
        tmp_pose = Pose()
        pyrosetta.rosetta.core.pose.append_pose_to_pose(
            tmp_pose, pose_chains[0], new_chain=True
        )
        pyrosetta.rosetta.core.pose.append_pose_to_pose(
            tmp_pose, pose_chains[1], new_chain=True
        )
        # fix the fasta by splitting on chainbreaks '/' and rejoining the first two
        tmp_fasta_dict = {
            tag: "/".join(seq.split("/")[0:2]) for tag, seq in tmp_fasta_dict.items()
        }
        # change the pose to the modified pose
        pose = tmp_pose.clone()
        print_timestamp("Setting up for AF2", start_time)
        runner = SuperfoldRunner(
            pose=pose, fasta_path=fasta_path, load_decoys=True, **kwargs
        )
        runner.setup_runner(file=fasta_path)
        # initial_guess, reference_pdb both are the tmp.pdb
        initial_guess = str(Path(runner.get_tmpdir()) / "tmp.pdb")
        reference_pdb = initial_guess
        flag_update = {
            "--initial_guess": initial_guess,
            "--reference_pdb": reference_pdb,
        }
        # now we have to point to the right fasta file
        new_fasta_path = str(Path(runner.get_tmpdir()) / "tmp.fa")
        dict_to_fasta(tmp_fasta_dict, new_fasta_path)
        runner.set_fasta_path(new_fasta_path)
        runner.override_input_file(new_fasta_path)
        runner.update_flags(flag_update)
        runner.update_command()
        print_timestamp("Running AF2", start_time)
        runner.apply(pose)
        print_timestamp("AF2 complete, updating pose datacache", start_time)
        # update the scores dict
        scores.update(pose.scores)
        # update the pose with the updated scores dict
        for key, value in scores.items():
            pyrosetta.rosetta.core.pose.setPoseExtraScore(pose, key, value)
        # Phil's for filtering crispy shifties
        if "filter_str" in kwargs.keys():
            filter_str=kwargs.pop("filter_str")
            if filter_str=="no_filter":
                filter_dict={}
            else:
                operator_dict={'lt':lt,'gt':gt}
                filter_dict={item.split(',')[0]:(operator_dict[item.split(',')[1]],float(item.split(',')[2])) for item in filter_str.split("#")}
        else:
            filter_dict = {
                "mean_plddt": (gt, 93.0),
                "rmsd_to_reference": (lt, 1.5),
                "mean_pae_interaction": (lt, 5),
            }
        rank_on = "mean_plddt"
        prefix = "mpnn_seq"
        print_timestamp("Generating decoys", start_time)
        for decoy in generate_decoys_from_pose(
            pose,
            filter_dict=filter_dict,
            generate_prediction_decoys=True,
            label_first=True,
            prefix=prefix,
            rank_on=rank_on,
        ):
            decoy_scores = dict(decoy.scores)
            bfactors={(r,a):decoy.pdb_info().bfactor(r,a) for r in range(1,decoy.total_residue()+1) for a in range(1,decoy.residue(r).natoms()+1)}
            # add the free state back into the decoy
            for other_chain in pose_chains[2:]:
                pyrosetta.rosetta.core.pose.append_pose_to_pose(
                    decoy, other_chain, new_chain=True
                )
            # clean ostensibly disulfide-bonded cysteines individually because they have unspecified partners
            if clean_disulfides:
                seq = decoy.sequence()
                all_cys_resi_indexes = [
                    i for i, r in enumerate(seq, start=1) if r == "C"
                ]
                for i in all_cys_resi_indexes:
                    if decoy.conformation().residue(i).type().is_disulfide_bonded():
                        pyrosetta.rosetta.core.conformation.change_cys_state(
                            i, "", decoy.conformation()
                        )

            # get the chA sequence
            chA_seq = decoy.chain_sequence(
                1
            )  # list(decoy.split_by_chain())[0].sequence()
            # setup SimpleThreadingMover
            stm = pyrosetta.rosetta.protocols.simple_moves.SimpleThreadingMover()
            # thread the sequence from chA onto chA
            stm.set_sequence(chA_seq, start_position=decoy.chain_begin(3))
            stm.apply(decoy)
            scom=pyrosetta.rosetta.protocols.simple_moves.SwitchChainOrderMover()
            scom.chain_order("".join([str(x) for x in range(1,decoy.num_chains()+1)]))
            scom.apply(decoy)
            for ra,b in bfactors.items():
                decoy.pdb_info().bfactor(ra[0],ra[1],b)
                print(decoy.pdb_info().bfactor(ra[0],ra[1]),flush=True)
            # rename af2 metrics to have Y_ prefix
            for key, value in decoy_scores.items():
                if key in af2_metrics:
                    pyrosetta.rosetta.core.pose.setPoseExtraScore(
                        decoy, f"Y_{key}", value
                    )

            packed_decoy = io.to_packed(decoy)
            yield packed_decoy
